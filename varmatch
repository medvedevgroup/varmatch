#!/usr/bin/env python

"""
Copyright 2015, Chen Sun

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

"""
    Authors:
    Chen Sun(chensun@cse.psu.edu)
    Paul Medvedev(pashadag@cse.psu.edu)
"""
from __future__ import print_function
import sys
versionError = "You are using an old version of python, please upgrade to python 2.7+\n"
if sys.hexversion < 0x02070000:
    print (versionError)
    exit()
import textwrap as _textwrap
import multiprocessing
import argparse
import os
import subprocess
import time

RUN = True

author_email = 'chensun@cse.psu.edu'

class SmartFormatter(argparse.HelpFormatter):
    def _split_lines(self, text, width):
        paragraphs = text.split('\n')
        #return paragraphs
        multiline_text = []
        for paragraph in paragraphs:
            formatted_paragraph = _textwrap.wrap(paragraph, width)
            multiline_text = multiline_text + formatted_paragraph
        return multiline_text

    def _fill_text(self, text, width, indent):
        return ''.join(indent + line for line in text.splitlines(True))

citation = 'Please cite our paper.'

parser = argparse.ArgumentParser(prog="varmatch", epilog = citation, formatter_class=lambda prog: SmartFormatter(prog,max_help_position=8))
parser.add_argument('-b', '--baseline', required=True, metavar='File', help = 'baseline variant VCF filename')
parser.add_argument('-q', '--query', nargs='+', metavar='File List', help = 'query variant VCF filename')
parser.add_argument('-g', '--genome', required=True, metavar='File', help= 'genome sequence FASTA filename')
parser.add_argument('-o', '--output', help='output directory', metavar='DIRECTORY',default='./output')

thread_string = "number of threads, default is the number of available cores (For this machine:" + str(multiprocessing.cpu_count()) + \
                ")\nIf larger than number of available cores or less than 1, automatically set to default value"

parser.add_argument('-t', '--thread', metavar="INT", help=thread_string, default=str(multiprocessing.cpu_count()))

score_unit_string = "scoring function/score unit: (Default: -1)\n"\
    "-1 : iterate both 0 and 1.\n"\
    "0  : the score that a VCF entry contributes is 1.\n"\
    "1  : the score that a VCF entry contributes is the edit distance between the new allele and the reference one.\n"

match_mode_string = "matching mode: (Default: -1)\n"\
    "-1 : iterate both 0 and 1.\n"\
    "0  : a set of query entries match a set of baseline entries if, "\
    "for each entry, we can select one of the alleles such that the inferred sequences are identical\n"\
    "1  : a set of query entries match a set of baseline entries if there exist a phasing of each set such that "\
    "the two inferred haplotypes from the query are equal to the two inferred haplotypes from the baseline.\n"

score_scheme_string = "scoring scheme: (Default: -1)\n"\
    "-1 : iterate 0, 1, and 2 (excluding 3)\n"\
    "0  : find two subsets of non-overlapping equivalent variants such that "\
    "the score of the matched variants is maximized \n"\
    "1  : find two subsets of non-overlapping equivalent variants such that"\
    " the score of the chosen baseline variants is maximized\n"\
    "2  : find a maximum scoring set of variants in the query such that"\
    " each variant can be matched by a subset of the baseline variants\n"\
    "3  : (1 to 1 direct match) find a maximum scoring set of entry pairs such that each entry pair contains"\
    " one query and one baseline variant that result in the same sequence."\
    " In this scheme, different scoring functions and "\
    "matching mode have no difference.\n"

parser.add_argument('-u', '--score_unit', help=score_unit_string, metavar='[-1,0,1]', default=-1)

parser.add_argument('-m', '--match_mode', help=match_mode_string, metavar='[-1,0,1]', default=-1)

parser.add_argument('-s', '--score_scheme', help=score_scheme_string, metavar='[-1,0,1,2,3]', default=-1)

parser.add_argument('-G', '--no_graph', help='disable graphic module', action = 'store_true')

disable_curves_string = "disable Precision-Recall curves, if use -G or --no_graph,"\
                        " then automatically disable these curves"

parser.add_argument('-C', '--disable_curves', help=disable_curves_string, action='store_true')

fast_mode_string = "In this mode, automatically disable graphic module and precision-recall curves,"\
                   " only performs one matching criterion.\n"\
                   " Fast mode is equivalent to use following parameters compulsively: -G -u 0 -m 0 -s 0"

parser.add_argument('-f', '--fast_mode', help=fast_mode_string, action='store_true')

args = parser.parse_args()

if(args.fast_mode):
    args.no_graph = True
    args.score_unit = 0
    args.match_mode = 0
    args.score_scheme = 0


def shell_run(command, hide=False):
    if not RUN:
        time.sleep(3.5)
        print(command)
    else:
        print(command)
        if hide:  # hide output
            FNULL = open(os.devnull, 'w')
            subprocess.call(command, shell=True, stdout=FNULL, stderr=subprocess.STDOUT)
            # subprocess.call(command, shell=True, stdout=FNULL)
            FNULL.close()
        else:
            subprocess.call(command, shell=True)


def check_command(command):
    """
    check if corresponding command available
    """
    if os.path.isfile(command):
        return True

    for cmdpath in os.environ['PATH'].split(':'):
        if os.path.isdir(cmdpath) and command in os.listdir(cmdpath):
            return True
    return False


def table_2_html(table):
    html = '<table border=.5>'
    for i in range(len(table)):
        if i == 0:
            html += '<tr><th>' + '</th><th>'.join(table[i]) + '</th></tr>'
        else:
            html += '<tr><td>' + '</td><td>'.join(table[i]) + '</td></tr>'

    html += '</table>'
    return html

html_head = """
<html>
<head>
<style type="text/css">
table, th, td {
    border: 1px solid black;
    border-collapse: collapse;
}
th, td {
    padding: 5px;
    text-align: left;
}

.box{
    border: 4px solid #ccc;
    padding:20px;
    margin:10px 100px 100px 10px;
}
#advhelp{
    display:none;
}
#advhelp:target{
    display:block;
}
</style>
</head>
<body>
"""

html_tail="""
</body>
</html>
"""

marker_list = ['o', 'v', '1', '8', 's', 'p', '*', 'h', 'x', 'D']

def multiple_compare(baseline_file, query_list, genome_file):
    global check_compare_command
    global output_dir
    if not check_compare_command and not check_command(compare_tool):
        print ('Error: can not find program: ' + compare_tool)
        print ('\t Try "make" command before execute, or contact author for support: ' + author_email)
        exit()
    else:
        check_compare_command = True
    compare_command = compare_tool + ' -b ' + baseline_file + ' -g ' + genome_file + ' -o ' + output_dir

    for query_file in query_list:
        compare_command += ' -q ' + query_file

    if args.thread is not None and int(args.thread) > 0:
        compare_command += ' -t ' + args.thread

    compare_command += ' -u ' + str(args.score_unit) + ' -m ' + str(args.match_mode) + ' -s ' + str(args.score_scheme)

    if args.no_graph or args.disable_curves:
        compare_command += ' -C '

    shell_run(compare_command)


def varmatch_pairwise(baseline_file, query_file, genome_file):
    global output_dir
    ref_basename = os.path.basename(baseline_file)
    que_basename = os.path.basename(query_file)
    output_prefix = output_dir + '/' + ref_basename + '_' + que_basename
    #pairwise_compare(baseline_file, query_file, genome_file)
    return output_prefix

def create_table_prefx(score_unit, match_mode, score_scheme):
    matching_id = ''
    score_unit_string = 'Unit Cost[U]'
    match_mode_string = 'Genotype[G]'
    score_scheme_string = 'Total[T]'
    if(score_unit == '0'):
        matching_id += 'U'
    else:
        matching_id += 'E'
        score_unit_string = 'Edit Distance[E]'

    if match_mode == '0':
        matching_id += 'G'
    else:
        matching_id += 'V'
        match_mode_string = 'Variant[V]'

    if score_scheme == '0':
        matching_id += 'T'
    elif score_scheme == '1':
        matching_id += 'B'
        score_scheme_string = 'Baseline[B]'
    elif score_scheme == '2':
        matching_id += 'Q'
        score_scheme_string = 'Query[Q]'

    return [matching_id, score_unit_string, match_mode_string, score_scheme_string]


def parse_stat(output_prefix):
    global output_dir
    stat_filename = output_dir + '/' + output_prefix + '.stat'
    no_filter_table = []
    head = ['Matching Id', 'Score Unit', 'Match Mode', 'Score Scheme', 'Baseline Match Number', 'Query Match Number', 'Recall(%)', 'Precision(%)']
    match_id = 0
    no_filter_table.append(head)
    x = [] # matching id list
    y = [] # sensitivity list
    z = [] # specificity list

    sensitivity_table = []
    specificity_table = []

    baseline_num = 0.
    query_num = 0.
    with open(stat_filename) as stat_file:
        for line in stat_file.readlines():
            line = line.strip()
            if line.startswith('##'):
                columns = line.split(':')
                if columns[0] == '##Baseline':
                    baseline_num = float(columns[1])
                else:
                    query_num = float(columns[1])
            if line.startswith('#'):
                continue
            match_id += 1
            temp = line.split('\t')
            row = create_table_prefx(temp[0], temp[1], temp[2])
            baseline_match_str_list = temp[4].split(',')
            query_match_str_list = temp[5].split(',')
            query_total_str_list = temp[6].split(',')

            baseline_match_str = baseline_match_str_list[0]
            query_match_str = query_match_str_list[0]

            sensitivity_list = []
            specificity_list = []
            tn_list = []
            for baseline_match_num in baseline_match_str_list:
                try:
                    sensitivity = float(baseline_match_num) * 100 / baseline_num # this is actually recall
                except ZeroDivisionError:
                    sensitivity = 0.0
                    
                sensitivity_list.append(sensitivity)
            #for query_match_num in query_match_str_list:
            #    specificity = float(query_match_num) * 100 / query_num # this is actually precison
            #    specificity_list.append(specificity)
            for i in range(len(query_match_str_list)):
                try:
                    specificity = float(query_match_str_list[i]) * 100 / float(query_total_str_list[i])
                except ZeroDivisionError:
                    specificity = 0.0

                specificity_list.append(specificity)

            x.append(row[0])
            row += [baseline_match_str, query_match_str, "%.3f" % sensitivity_list[0], "%.3f" % specificity_list[0]]

            y.append(sensitivity_list[0])
            z.append(specificity_list[0])

            sensitivity_table.append(sensitivity_list)
            specificity_table.append(specificity_list)
            no_filter_table.append(row)

    return baseline_num, query_num, x, y, z, no_filter_table, sensitivity_table, specificity_table


def create_table_by_matchingid_from_by_query(table_list, matching_list, query_number):
    table_by_matchingid = []
    for matching_index in range(len(matching_list)):
        matching_table = []
        title = ['Query Id', 'Baseline Match Number', 'Query Match Number', 'Recall(%)', 'Precision(%)']
        matching_table.append(title)
        for table_index in range(len(table_list)):
            raw_row = table_list[table_index][matching_index]
            new_row = ['Query' + str(table_index+1)]
            new_row += raw_row[4:]
            matching_table.append(new_row)
        table_by_matchingid.append(matching_table)
    return table_by_matchingid


# all html and picture are created from stat file, not parameters
def create_stat_html(query_list, output_prefix_list):
    global output_dir
    html_filename = output_dir + '/stat.html'
    html_file = open(html_filename, 'w')
    html_file.write(html_head)
    html_file.write('<h1>VarMatch Report</h1>')
    html_file.write('<p>precison and recall analysis for each query with variant quality &ge; 0</p>')
    exp_num = len(output_prefix_list)
    baseline_num_list = []
    query_num_list = []
    table_list = []
    label_list = []
    sensitivity_list = []
    specificity_list = []
    sensitivity_table_list = []
    specificity_table_list = []

    for output_prefix in output_prefix_list:
        (baseline_num, query_num, x, y, z, table, sensitivity_table, specificity_table) = parse_stat(output_prefix)
        baseline_num_list.append(int(baseline_num))
        query_num_list.append(int(query_num))
        label_list.append(x)
        sensitivity_list.append(y)
        specificity_list.append(z)
        table_list.append(table)

        print(sensitivity_table)
        print(specificity_table)

        sensitivity_table_list.append(sensitivity_table)
        specificity_table_list.append(specificity_table)

    if(len(table_list)) == 0:
        html_file.close()
        return

    if not args.no_graph:
        import numpy as np
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        axes = plt.gca()
        #axes.set_xlim([xmin,xmax])
        axes.set_ylim([0,100])
        for i in range(exp_num):
            marker_id = i % len(marker_list)
            marker_sign = marker_list[marker_id]
            label_sign = 'Query ' + str(i+1)
            x = np.array(range(len(label_list[0])))
            plt.xticks(x, label_list[0])
            plt.plot(x, sensitivity_list[i], marker = marker_sign, linestyle = '-', label = label_sign)

        plt.xlabel('Matching Id')
        plt.ylabel('Recall(%)')
        #plt.title('Sensitivity of Queries under Different Matching Parameters')
        plt.legend(loc='best')
        plt.savefig(output_dir + '/sensitivity.png')

        plt.clf() # clear figure for the next
        axes = plt.gca()
        #axes.set_xlim([xmin,xmax])
        axes.set_ylim([0,100])
        for i in range(exp_num):
            marker_id = i % len(marker_list)
            marker_sign = marker_list[marker_id]
            label_sign = 'Query ' + str(i+1)
            x = np.array(range(len(label_list[0])))
            plt.xticks(x, label_list[0])
            plt.plot(x, specificity_list[i], marker = marker_sign, linestyle = '-', label = label_sign)

        plt.xlabel('Matching Id')
        plt.ylabel('Precision(%)')
        #plt.title('Specificity of Queries under Different Matching Parameters')
        plt.legend(loc='best')
        plt.savefig(output_dir + '/specificity.png')

        html_file.write('<h2>VarMatch Matching Parameters Table</h2>'+'\n')
        parameter_table = []
        temp_table = table_list[0]
        for row in temp_table:
            parameter_table.append(row[:4])
        html_file.write(table_2_html(parameter_table))

        html_file.write('<h2>Sensitivity and Specificity of Queries under Different Matching Parameters</h2>'+'\n')
        html_file.write('<p> Baseline File: ' + args.baseline+'</p>' + '\n')
        for i in range(exp_num):
            html_file.write('<p> Query ' + str(i+1) + ': ' + query_list[i] + '</p>' + '\n')
        html_file.write('<h3>Recall of Queries under Different Matching Parameters</h3>'+'\n')
        html_file.write('<img src="sensitivity.png" alt="Sensitivity Graph Not Found...">'+'\n')
        html_file.write('<h3>Precison of Queries under Different Matching Parameters</h3>'+'\n')
        html_file.write('<img src="specificity.png" alt="Specificity Graph Not Found...">'+'\n')

    # sensitivity and specificity analysis by query
    html_file.write('<h2>Sensitivity and Specificity Analysis by Query</h2>'+'\n')

    for i in range(exp_num):
        html_file.write('<div class="box">')
        html_file.write('<h3>Query File: ' + query_list[i] + '</h3>'+'\n')
        html_file.write('<p> Number of Variants in Baseline: ' + str(baseline_num_list[i]) + '</p>'+'\n')
        html_file.write('<p> Number of Variants in Query: ' + str(query_num_list[i]) + '</p>'+'\n')
        html_file.write(table_2_html(table_list[i]))
        html_file.write('</div>'+'\n')

    if exp_num > 1:
        # sensitivity and specificity analysis by matching id
        html_file.write('<h2><Sensitivity and Specificity Analysis by Matching Id/h2>')

        table_by_matchingid = create_table_by_matchingid_from_by_query(table_list, label_list[0], exp_num)
        for i in range(len(label_list[0])):
            html_file.write('<div class="box">')
            html_file.write('<h3>Matching Id: ' + label_list[0][i] + '</h3>'+'\n')
            html_file.write(table_2_html(table_by_matchingid[i]))
            html_file.write('</div>'+'\n')

        html_file.write(html_tail)
        html_file.close()

    # create roc html
    if args.no_graph or args.disable_curves:
        return

    html_filename = output_dir + '/precision_recall.html'
    html_file = open(html_filename, 'w')
    html_file.write(html_head)
    html_file.write('<h1>VarMatch Precision-Recall Curves</h1>')

    html_file.write('<h2>VarMatch Matching Parameters Table</h2>'+'\n')
    parameter_table = []
    temp_table = table_list[0]
    for row in temp_table:
        parameter_table.append(row[:4])
    html_file.write(table_2_html(parameter_table))

    for i in range(exp_num):
        html_file.write('<p>Query ' + str(i+1) + ': ' + query_list[i] + '</p>' + '\n')

    html_file.write('<h2>Precision-Recall Curve by Matching Id</h2>')
    html_file.write('<p>For each matching id, compare all queries in one graph</p>')
    for i in range(len(parameter_table)-1):
        html_file.write('<h3>Precision-Recall Curve for Parameter '+parameter_table[i+1][0]+'</h3>'+'\n')

        plt.clf()

        for j in range(exp_num):
            x = sensitivity_table_list[j][i]
            y = specificity_table_list[j][i]

            x[:] = [a/100 for a in x]
            #y.reverse()
            y[:] = [a/100 for a in y]
            x.sort()
            y.sort(reverse=True)
            y = y[::-1]
            label_sign = 'Query ' + str(j+1)
            plt.plot(x,y, label = label_sign)

        #x = [0.0, 1.0]
        #plt.plot(x, x, linestyle='dashed', color='red', linewidth=2, label='random')

        plt.xlim(0.0, 1.0)
        plt.ylim(0.0, 1.0)
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.legend(loc='best')
        plt.tight_layout()
        plt.savefig(output_dir + '/parameter' + str(i)+'.roc.png')

        html_file.write('<img src="parameter'+str(i) + '.roc.png'+'" alt="ROC Curve Not Found">\n')

    html_file.write('<h2>Precision-Recall Curve by Query</h2>')
    html_file.write('<p>For each query, compare all matching id in one graph</p>')
    for i in range(exp_num):
        html_file.write('<h3>Precision-Recall Curve for Query '+str(i+1)+'</h3>'+'\n')

        plt.clf()

        colormap = plt.cm.gist_ncar
        plt.gca().set_color_cycle([colormap(k) for k in np.linspace(0, 0.9, len(parameter_table))])

        for j in range(len(parameter_table)-1):
            x = sensitivity_table_list[i][j]
            y = specificity_table_list[i][j]

            #x[:] = [1.0 - a/100 for a in x]
            #y.reverse()
            #y[:] = [a/100 for a in y]

            #x.sort()
            #y.sort(reverse=True)

            label_sign = parameter_table[j+1][0]
            plt.plot(x,y, label = label_sign)

        #x = [0.0, 1.0]
        #plt.plot(x, x, linestyle='dashed', color='red', linewidth=2, label='random')

        plt.xlim(0.0, 1.0)
        plt.ylim(0.0, 1.0)
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.legend(loc='best')
        plt.tight_layout()
        plt.savefig(output_dir + '/query' + str(i)+'.roc.png')

        html_file.write('<img src="query'+str(i) + '.roc.png'+'" alt="ROC Curve Not Found">\n')

    html_file.write(html_tail)
    html_file.close()



def main():
    if len(sys.argv) < 2:
        parser.print_help()
        exit()

    global check_compare_command
    global script_path
    global compare_tool
    global output_dir
    global temp_dir

    check_compare_command = True

    script_path = sys.path[0]
    compare_tool = script_path + '/src/vm-core'
    output_dir = ''
    temp_dir = ''

    # create output directory
    if args.output is None or args.output == '':
        output_dir = os.getcwd() + '/output'
    else:
        output_dir = args.output
    if output_dir == '':
        output_dir = os.getcwd() + '/output'
    if not os.path.exists(output_dir):
        os.mkdir(output_dir)

    temp_dir = output_dir + '/temp'

    query_list = args.query

    multiple_compare(args.baseline, query_list, args.genome)

    if args.score_scheme == '3':
        exit()
        
    output_prefix_list = []
    for i in range(len(query_list)):
        output_prefix_list.append('query'+str(i+1))

    create_stat_html(query_list, output_prefix_list)

if __name__ == '__main__':
    main()
